{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMBXniLty07a"
   },
   "source": [
    "# Lab 1\n",
    "\n",
    "## Topics covered:\n",
    "1. Intro to packages \n",
    "2. Data Science Life Cycle\n",
    "3. Data Structures in Python\n",
    "4. Pandas\n",
    "5. Visualizations and plotting with Dataframes\n",
    "6. Intro to APIs\n",
    "7. Intro to NLP tasks\n",
    "8. Regular Expressions\n",
    "9. Concordances and Collocations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:11:43.601217Z",
     "start_time": "2022-08-22T09:11:42.439897Z"
    },
    "id": "3uCkeoT5zXYV"
   },
   "outputs": [],
   "source": [
    "# load the packages we will use for the remainder of the lab.\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import regex as re \n",
    "\n",
    "# We are using shorthands for package names. This allows us to call these packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csWrf6EUAsb7"
   },
   "source": [
    "Understanding packages in python:\n",
    "The above cell **imports** certain \"packages\" which allow particular functionalities within the notebook. Each \"package\" has a documentation which you can check out for reference. It's generally good practice to consult these documentations for reference and help with code.\n",
    "\n",
    "* Numpy Basics: https://numpy.org/doc/stable/user/absolute_beginners.html\n",
    "\n",
    "* Data 8 Numpy manuplation guide: http://data8.org/su22/python-reference.html\n",
    "\n",
    "* Pandas: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "\n",
    "* Pandas Dataframe manuplation: https://https://pandas.pydata.org/docs/reference/frame.html\n",
    "\n",
    "* Matplotlib: https://matplotlib.org/stable/tutorials/introductory/usage.html\n",
    "\n",
    "The following video provides an insight into the data science lifecycle, aka steps taken to analyze data and produce results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:14:10.881816Z",
     "start_time": "2022-08-22T09:14:07.827289Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "wPxSeoZMAzsv",
    "outputId": "0ff62d3e-46bf-4647-9a4f-2d44903d0016"
   },
   "outputs": [],
   "source": [
    "## Do not edit this code block\n",
    "!pip install pytube \n",
    "## if you use an exclamation point, you are able to access the terminal, and thus install a package from the notebook\n",
    "## in this case, we're intalling \"pytube\" package which lets us view youtube videos inside the notebook\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('5I2bYqeFQy4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmHTKVEg5aly"
   },
   "source": [
    "# **Data Structures in Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1lAGTt98vQF"
   },
   "source": [
    "## String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1yJUnU884ge"
   },
   "source": [
    "In Python, a string is a sequence of Unicode characters. Strings can be created by enclosing characters inside a single quote or double-quotes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:20:06.545415Z",
     "start_time": "2022-08-22T09:20:06.539424Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oh1TSeiD85F5",
    "outputId": "8138eb5a-cb37-4e88-9969-cc6a519d9c79"
   },
   "outputs": [],
   "source": [
    "#All 4 strings are the same \n",
    "String = \"Hello World\" \n",
    "String = 'Hello World' \n",
    "String = \"\"\"Hello World\"\"\" \n",
    "String = \"Hello\" + \" \" + \"World\"\n",
    "print(String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:16:10.332698Z",
     "start_time": "2022-08-22T09:16:10.323719Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3XjG25M8_uc",
    "outputId": "67c2dd71-961b-4b52-a7f6-93316d330e2d"
   },
   "outputs": [],
   "source": [
    "first_letter = String[0] # Indexing in python start at 0 \n",
    "last_letter = String[-1] # Indexing into the last character \n",
    "for letter in String: # This is a for loop.\n",
    "  print(letter)       # What we are saying is - \"FOR every letter (or element) \n",
    "                                                #DO X - in this case, \"print\" each \"letter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h8lIYd-5mLr"
   },
   "source": [
    "## List\n",
    "Python **lists** are indexable data structures which can hold different kinds of data as **items**. They may look something like the following:\n",
    "\n",
    "```\n",
    "friends = ['Rachel', 'Chandler', 'Joey', 'Monica', 'Ross', 'Phoebe']\n",
    "\n",
    "odd_nums = [1, 3, 5, 7, 9]\n",
    "```\n",
    "\n",
    "To retrieve an element in a list, you would need to index into this list, starting with an index value of 0. For example, if you wanted to return the second integer in *odd_nums*, you would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:18:41.666973Z",
     "start_time": "2022-08-22T09:18:41.660973Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCY-D3x05zgA",
    "outputId": "a66414eb-240e-4056-c479-2ab2c6739282"
   },
   "outputs": [],
   "source": [
    "odd_nums = [1, 3, 5, 7, 9]\n",
    "odd_nums[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEwaSnL450Fe"
   },
   "source": [
    "**Question 1: Replace the ellipses and try to return 'Joey' from the `friends` list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAJwsXXF6NMQ"
   },
   "outputs": [],
   "source": [
    "friends = ['Rachel', 'Chandler', 'Joey', 'Monica', 'Ross', 'Phoebe']\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXl-gzQ67RQo"
   },
   "source": [
    "**Numpy array** is another data structure we commonly use in python. It works similar to a **list**, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxEdUS_B8HsP",
    "outputId": "85954c91-62b9-424a-e5c1-30daa3abef3b"
   },
   "outputs": [],
   "source": [
    "array = np.array([\"Appeals\" ,\"Supreme\", \"Court\" , \"Justice\"])\n",
    "#Prints the first and second item of the array \n",
    "print(array[0])\n",
    "print(array[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W7mGyUl6TPs"
   },
   "source": [
    "## Dictionary\n",
    "The **dictionary** data structure is useful for holding **pairs of data**, known as **\"key-value\"** pairs. Dictionaries look like \n",
    "\n",
    "```\n",
    "Dictionary = { key : value , key : value , key : value}\n",
    "```\n",
    "\n",
    "You might notice that unlike lists that use `[]`, dictionaries use `{}` followed by a **key : value pair**. Each key-value pair is seperated by a comma.\n",
    "\n",
    "For example if we wanted to create dictonary called \"states\" where:\n",
    "* the **key is the name of the state** \n",
    "* the **value is the state abbrevation**.\n",
    "\n",
    "\n",
    "we would use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:23:08.459012Z",
     "start_time": "2022-08-22T09:23:08.438981Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yr1iQR6N6ip5",
    "outputId": "cc7c28c5-688e-4f75-9e3b-7428e50eb8ea"
   },
   "outputs": [],
   "source": [
    "states = {\"California\" : 'CA',\n",
    "          \"Idaho\" : 'ID',\n",
    "          \"Nevada\" : 'NV'}\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN6qx3Rz6qi8"
   },
   "source": [
    "You can **access** the abbreviations by indexing into the dictionary with brackets and the key value. For example, if you want to return `VALUE` associated with `KEY`, you would do the following:\n",
    "\n",
    "```\n",
    "example_dict[KEY]\n",
    "```\n",
    "\n",
    "This would return `VALUE`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyRyEMlT6wzQ"
   },
   "source": [
    "**Question 2: How would you return the abbreviation for Nevada using the states dictionary above? Assign *result* to this expression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:23:29.699717Z",
     "start_time": "2022-08-22T09:23:29.683718Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yjwJBNtE7Cfj",
    "outputId": "9f3105a2-c277-41da-c4d5-34465f2fad83"
   },
   "outputs": [],
   "source": [
    "# Using the states dictionary above, assign result to 'ID' by replacing the ellipses\n",
    "result = states [\"Idaho\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6701lGCl4pSF"
   },
   "source": [
    "# **Loading and Inspecting Data with Pandas**\n",
    "First, we will use the pandas package to read in two different types of file formats csv and json. Both of these files are \"sample data\" from google colab.\n",
    "\n",
    "The functions **read_csv** and **read_json** take in one argument, the **file path** of the file you wish to read in. In this case, the file is in a directory called \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:40:53.707750Z",
     "start_time": "2022-08-22T09:40:53.629470Z"
    },
    "id": "ANjnD8RJzHQP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/california_housing_train.csv\")\n",
    "df2 = pd.read_json(\"data/anscombe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-daThC-z95H"
   },
   "source": [
    "Now that we have loaded in our DataFrames we want see our new table. Here are a few useful methods to see our table. \n",
    "\n",
    "* We can use the **`head()`** function to see the first 5 rows of our table. Alternatively we can use the `tail()` to see the last 5 rows of our table. \n",
    "* The **shape** method returns a tuple where the first item is the number of rows and the second is the number columns in the table. \n",
    "\n",
    "```\n",
    "df.head()\n",
    "df.tail()\n",
    "df.shape\n",
    "```\n",
    "\n",
    "* Now that we know what are table looks like and the shape of it, we can use the **`describe()`** function to see basic summary statistics from our table. \n",
    "\n",
    "```\n",
    "df.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:41:49.863520Z",
     "start_time": "2022-08-22T09:41:49.839524Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "hS-_G9yPz3kW",
    "outputId": "21146897-ae9f-4f98-f608-1305375f3840"
   },
   "outputs": [],
   "source": [
    "# Show first 5 rows of our data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:41:53.106321Z",
     "start_time": "2022-08-22T09:41:53.088334Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "tvM0mVc8z3mv",
    "outputId": "39cb0574-cad9-4680-8d4c-0ae13484be0a"
   },
   "outputs": [],
   "source": [
    "# Show last 5 rows of our data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:41:58.359871Z",
     "start_time": "2022-08-22T09:41:58.344838Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQdcJK5Hz3pM",
    "outputId": "992eb78e-4100-4ca1-e72c-682b27208dc2"
   },
   "outputs": [],
   "source": [
    "rows , columns = df.shape[0] , df.shape[1]\n",
    "print(\"The number of rows is: \" + str(rows), \"  The number of columns is: \" + str(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:42:01.663929Z",
     "start_time": "2022-08-22T09:42:01.597929Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "924E0-_01C-P",
    "outputId": "788f3e31-f6b1-4a8b-f247-19db1629da1d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7bl9tVD1OD3"
   },
   "source": [
    "## **Manipulating the DataFrame**\n",
    "Next we will cover dropping unwanted values and duplicate rows using **`dropna()`** and **`drop_duplicates()`** respectively. Both of these functions return a new DataFrame without changing the original by default. \n",
    "\n",
    "In order to store the new table you will have to **assign it to a variable**. This is generally the default behavior for most Pandas functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:42:33.551764Z",
     "start_time": "2022-08-22T09:42:33.525759Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "MvCOU39a1DDk",
    "outputId": "0c123d85-6f26-4a10-9d23-b8e86b325c27"
   },
   "outputs": [],
   "source": [
    "new_df = df.dropna()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:42:40.242457Z",
     "start_time": "2022-08-22T09:42:40.226457Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBBuH9l81-9A",
    "outputId": "2ade4d84-66ce-47fe-e9b1-95ea6a1c414e"
   },
   "outputs": [],
   "source": [
    "print('The number of rows after droping N/A values is', new_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:42:42.922034Z",
     "start_time": "2022-08-22T09:42:42.894013Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "taYb6yaH1uOC",
    "outputId": "fbe677e3-ad23-4191-c037-535ed8a8a7ba"
   },
   "outputs": [],
   "source": [
    "new_df = new_df.drop_duplicates()\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CZ1VbVk2MSz",
    "outputId": "67da19dd-2c03-42fd-9d30-7200ae725e9c"
   },
   "outputs": [],
   "source": [
    "print('The number of rows after droping duplicate values is',new_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBJWY3bW2UAx"
   },
   "source": [
    "Hooray! Seems like our data doesn't have any N/A or duplicate values. Then we can proceed to explore more of our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WOLU8WC2_tE"
   },
   "source": [
    "One way to manipulate DataFrame tables is to use **`df['column name']`** to return one column of the table. \n",
    "\n",
    "In the example below we look at the **housing_median_age** column and use **`value_counts()`** to see how many times each unique value appears. Similarly, you can also apply other functions to columns. \n",
    "\n",
    "Adding new columns also uses this **`[\"column name\"]`** syntax. You can specify **`df[\"column name\"]`** and set it equal to the data you want to add. For example if you wanted to add a column of names with all upper case letters.\n",
    "```\n",
    "df[\"upper_case_names\"] = df[\"names\"].str.upper() \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:43:32.503437Z",
     "start_time": "2022-08-22T09:43:32.481439Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gN7avMQk3qod",
    "outputId": "2802a766-23f3-443b-a9f0-9dab6c511931"
   },
   "outputs": [],
   "source": [
    "df['housing_median_age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v47v9-DP33cT"
   },
   "source": [
    "**Question 3: How would you add a column for log population? Replace ... with your answer. (Hint use np.log())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "i_x3_OU2251j",
    "outputId": "9be845bf-5774-4240-e2f3-377b4be2d29b"
   },
   "outputs": [],
   "source": [
    "df[\"log_population\"] = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxSVkshR4KtZ"
   },
   "source": [
    "You can also use \n",
    "\n",
    "```\n",
    "df[df[\"column\"] == Condition]\n",
    "```\n",
    "to only keep rows where a certain condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:44:14.954152Z",
     "start_time": "2022-08-22T09:44:14.930146Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "8ouGbifg4KPJ",
    "outputId": "b6edd37c-5e1f-4fec-b117-75db1e221c39"
   },
   "outputs": [],
   "source": [
    "# Example: Only keep rows where population is above the average\n",
    "df[df[\"population\"] > np.mean(df[\"population\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2Z_ReFD4eo4"
   },
   "source": [
    "If you want to select more than one column at a time and/or a certain number of rows you can use \n",
    "\n",
    "\n",
    "```\n",
    "df.loc(: , ['column_name' , 'column_name']) \n",
    "```\n",
    "\n",
    "where the first argument is the index you want and the second argument is the list of columns you want. \n",
    "\n",
    "The \" : \" after **`.loc(`**  is shorthand for **all**. This example gives you all the rows for the two columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIURErx442ZS"
   },
   "source": [
    "# Plotting with DataFrames\n",
    "## Histograms\n",
    "Histograms are a nifty way to display quantitative information. The x-axis is typically a quantitative variable of interest, and the y-axis is generally a frequency. Plot a histogram of the losses, and then experiment with the bin sizes by uncommmenting out the italicized text (removing the # symbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:47:23.272060Z",
     "start_time": "2022-08-22T09:47:22.645060Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "oYVWEaZJBNfs",
    "outputId": "c9bace3a-0053-47a8-d274-82cd16cac7a7"
   },
   "outputs": [],
   "source": [
    "df.hist(\"median_house_value\", grid = False)\n",
    "\n",
    "# Try uncommenting the following lines and see the different results. What does this tell you about the parameters used?\n",
    "\n",
    "#df.hist(\"median_house_value\",bins = range(0,500000,1000) ,grid = False)\n",
    "#df.hist(\"median_house_value\" ,grid = False)\n",
    "#df.hist(\"median_house_value\",grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuESGb55Bg_d"
   },
   "source": [
    "## Scatter Plots\n",
    "Scatter plots are generally used to relate two variables to one another. They can be useful when trying to infer relationships between variables, visualize simple regressions, and get a general sense of the \"spread\" of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T09:47:33.615206Z",
     "start_time": "2022-08-22T09:47:33.435202Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "7z3S3AyPBeaY",
    "outputId": "68469ae7-a6fa-4236-9d49-c9969985ebb7"
   },
   "outputs": [],
   "source": [
    "# Median house value vs Median income. Do you spot a correlation?\n",
    "df.plot.scatter(x = \"median_income\", \n",
    "                y = \"median_house_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-VUiGIw9IF8"
   },
   "source": [
    "# Part 2: Introduction to API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LS190 , we'll be extensively working with the **[case.law](https://case.law/)** database - which is a database of **360 years of United States caselaw.** To access this data we'll need to develop a simple understanding of APIs.\n",
    "\n",
    "* API is the acronym for **Application Programming Interface** - a pretty vague acronym, if you ask me (unless you are a CS person who can explain what this means). The term itself most likely comes from the early days of computing. \n",
    "\n",
    "* For the purposes of this class, the important thing to note is that an **API allows us to interact with, access and download data from the case.law database.** This is why a **[case.law API KEY](https://case.law/docs/site_features/api)** becomes important - as this key allows you to download the case.law data. You can think of an API key as a magical phrase like \"Open Sesame\" - which lets you access a database where hidden treasures of data await.\n",
    "\n",
    "* The overwhelming amounts of data has made **APIs and API KEYS** the standard means of accessing data. Different organizations which store data have different means of accessing it. For example, there's the **[Twitter API](https://developer.twitter.com/en/docs/twitter-api)** if you want to study tweets. Or **[NYTimes API](https://developer.nytimes.com/apis)** if you want to study the New York Times Archive.\n",
    "\n",
    "The API for case.law is very-well documented and you can find examples of how to use the API by following the various **[jupyter notebooks they provided](https://github.com/harvard-lil/cap-examples)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:11:28.973070Z",
     "start_time": "2022-08-22T10:11:28.853047Z"
    },
    "id": "Nmt87jZXgsuj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import lzma\n",
    "import json\n",
    "\n",
    "from config import settings_base as settings \n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we are importing a couple of libraries. \n",
    "* **`lzma`** allows us to decompress the case.law data\n",
    "* **`json`** allows us to access the *dictionary* data structure \n",
    "* **`config`** is a folder which contains **settings_base** python script. This script should contain your **API KEY** \n",
    " * Note that each API key is unique and different. Because these notebooks are published on github, we cannot share the API Key. This is why I ask you to get the API key from the kind folks at case.law as soon as possible.\n",
    "* Finally, **`utils`** is a python script which contains helper functions written by case.law folks which allow us to download their data.\n",
    "\n",
    "The examples code below is based on the **[example notebooks](https://github.com/harvard-lil/cap-examples)**  example notebooks  written by the wonderful people working at case.law. The case.law project is incredibly important as it allows us to access **huge amounts of case text data** without having to pay subscription for services like LexisNexis or Westlaw. This is a wonderful example of data democratization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:11:58.251704Z",
     "start_time": "2022-08-22T10:11:32.101464Z"
    },
    "id": "fATB2Hdhsa3n"
   },
   "outputs": [],
   "source": [
    "# Get Case Data for Hawaii (as it's a small-ish jurisdiction)\n",
    "compressed_file = utils.get_and_extract_from_bulk(jurisdiction=\"Hawaii\", \n",
    "                                                  data_format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:22:37.246311Z",
     "start_time": "2022-08-22T10:22:37.242326Z"
    },
    "id": "HNuUBD8DXBnX"
   },
   "outputs": [],
   "source": [
    "# Assume we are dealing with json data (if data_format is changed to xml or\n",
    "# change this cell's os.path.join line)\n",
    "if not compressed_file.endswith('.xz'):\n",
    "  compressed_file = os.path.join(compressed_file, \"data\", \"data.jsonl.xz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:23:23.262527Z",
     "start_time": "2022-08-22T10:22:41.786573Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0NIKWEPsfIF",
    "outputId": "75b9a2e1-29cc-471e-aec2-170969a0b1bf"
   },
   "outputs": [],
   "source": [
    "cases = []\n",
    "print(\"File path:\", compressed_file)\n",
    "with lzma.open(compressed_file) as infile:\n",
    "    for line in infile:\n",
    "        record = json.loads(str(line, 'utf-8'))\n",
    "        cases.append(record)\n",
    "\n",
    "print(\"Case count: %s\" % len(cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:23:23.961528Z",
     "start_time": "2022-08-22T10:23:23.265510Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "smiRy_M3siNq",
    "outputId": "877effb5-053c-404c-aed9-be2f61f2a7a4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cases)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have access to case.law data, Hawaii dataset. Fascinating!\n",
    "\n",
    "You can explore the data further here if you'd like. Note that the actual **text** is contained within a dictionary in the column named **casebody.** We will be exploring how to access the text of decisions below when we will be introducing **concordances**\n",
    "\n",
    "Note:\n",
    "I also, again, encourage you to check out the case.law **[example notebooks](https://github.com/harvard-lil/cap-examples)**. For instance, the **[Cartwright notebook - which shows who was Illinois' most prolific judge](https://github.com/harvard-lil/cap-examples/blob/develop/bulk_exploration/cartwright.ipynb)** is pretty fascinating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOnadrCz_4SR"
   },
   "source": [
    "# Part 3: Introduction to NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1kwIIDaB7IG"
   },
   "source": [
    "## **Spacy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRAst2E6ADhm"
   },
   "source": [
    "**[spacy](https://spacy.io/usage/spacy-101#features)** is an open-source NLP library which we'll be using to analyze features about textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:29:05.882754Z",
     "start_time": "2022-08-22T10:28:53.233054Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dabEbEUZAGjS",
    "outputId": "0c2ba945-4efc-4e92-f46d-209b98362060"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"Today, I had a great time visiting Disneyland!\"\n",
    "\n",
    "# Configures pipeline for language processing - \n",
    "# we're basically loading a model called \"en_core_web_sm\" - a trained model for English language\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Creates a pipeline for the string associated with variable \"text\"\n",
    "pipe = nlp(text)\n",
    "\n",
    "for token in pipe:\n",
    "  print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iIkUmNNAMk3"
   },
   "source": [
    "Python's `split()` function is similar, but you'll notice that it's not so easy to separate words from punctuation, as compared to spaCy's tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:29:57.065111Z",
     "start_time": "2022-08-22T10:29:57.047111Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1VL0dMWAZcR",
    "outputId": "dbdfe01c-7a72-4c9a-8d58-4d33dabc32bd"
   },
   "outputs": [],
   "source": [
    "# splitting on whitespace\n",
    "text.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziPDOipMAeb7"
   },
   "source": [
    "**spaCy** is great because it's easy to retrieve various elements about the tokens within your text. We run a model that's already available - namely \"en_core_web_sm\"\n",
    "\n",
    "For example, say with every token, you wanted to know the **part-of-speech** - is it a Verb or a Noun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:31:16.554854Z",
     "start_time": "2022-08-22T10:31:16.546852Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JEIH21uAg7i",
    "outputId": "e8062bf0-692d-4bd0-b97f-7e1fcc980abe"
   },
   "outputs": [],
   "source": [
    "token_pos_pairs = []\n",
    "\n",
    "for token in pipe:\n",
    "  token_pos_pairs.append([token, token.pos_])\n",
    "\n",
    "token_pos_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_UXi7mPAojB"
   },
   "source": [
    "The \"lemma\" of a word can be considered its base form. For example, *eating*, *ate*, and *eat* all have the same lemma: *eat*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tR4VXdGnA6mK"
   },
   "source": [
    "**Question 5: Using the for loop above as inspiration, create a list `token_lemma_pairs`. This list will be the same shape as token_pos_pairs, but contain the lemma rather than part-of-speech.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8TK2yYfaBK1O",
    "outputId": "74764278-5e53-4a1b-848f-e17c84a8d899"
   },
   "outputs": [],
   "source": [
    "token_lemma_pairs = []\n",
    "\n",
    "for token in pipe:\n",
    "  ...\n",
    "\n",
    "# The shape of token_lemma_pairs should match token_pos_pairs in the last coding cell\n",
    "token_lemma_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE78hnr3Bdjb"
   },
   "source": [
    "Let's say now, we want to create a dictionary with the keys being terms within a text, and values being the number of times the terms are present. In this case, tokenization with spacy can help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYjWZkjFBnnv",
    "outputId": "37c7c985-488e-4fb9-e6e2-15a1829b93ee"
   },
   "outputs": [],
   "source": [
    "text = \"Hey, what'd you think about the new movie?\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pipe = nlp(text).to_array('LANG')\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_uKr1zYEBp1s",
    "outputId": "79525ede-e8f2-498a-b7c9-d4615c90b64b"
   },
   "outputs": [],
   "source": [
    "# Replace the 4 ellipses in the for-loop\n",
    "\n",
    "# word_counts is a dictionary with tokens as the keys and counts as the values\n",
    "word_counts = {}\n",
    "\n",
    "# Creates a pipeline of tokens for our text\n",
    "text = \"hi hi hi hi hi hey hello hey\" #REPLACE WITH A FILE!!!! This is just a test\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pipe = nlp(text)\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for token in pipe:\n",
    "  tokens.append(str(token))\n",
    "\n",
    "# word_counts[KEY] accesses a VALUE (count) associated with a KEY (token/word)\n",
    "for token in tokens:\n",
    "  # If the word already exists in the dictionary, what should you do to its count? \n",
    "  if token in word_counts:\n",
    "    word_counts[token] += 1\n",
    "  # What if it doesn't exist?\n",
    "  else:\n",
    "    word_counts[token] = 1\n",
    "\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsYkmeMsCBFy"
   },
   "source": [
    "# **REGEX - Regular Expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei3cPafKCCms"
   },
   "source": [
    "**Sets, Quantifiers, and Special Characters**\n",
    "\n",
    "Regex (regular expressions) is a very powerful tool to find patterns in text. One of the best ways to learn Regex is by using Regex 101 to practice matching words in a body of text.\n",
    "\n",
    "[Regex101](https://regex101.com/)\n",
    "\n",
    "[Regex Reference Sheet](http://www.rexegg.com/regex-quickstart.html#ref)\n",
    "\n",
    "For example, say we had a text and we wanted to find every instance of a word within that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBeFZsbJCJqK",
    "outputId": "42473dd9-c5d7-4043-a836-6bee70f9caaf"
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "import regex as re\n",
    "text = \"Samuel and I went down to the river yesterday! Samuel isn't a very good swimmer, though. Good thing our friend Sahit was there to help.\"\n",
    "\n",
    "# the findall() function finds every instance of a specified word pattern within a text\n",
    "re.findall(r'Samuel', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3RTPiIhCOi5"
   },
   "source": [
    "Let's say that instead of only wanting to find Samuel, we wanted to find every word in the text starting with 'Sa'. What would we do? Use pattern matching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kndfT3OeCNh9",
    "outputId": "312fffa7-d93f-486f-f7e5-d43e7595fd97"
   },
   "outputs": [],
   "source": [
    "re.findall(r'Sa[a-z]*', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLgX7o7ICU3p"
   },
   "source": [
    "You may be wondering what the [a-z] in the Sa[a-z] pattern means. This is called a **set** in regex. When characters are within a set, such as  [abcde], any one character will match. However, regex has a special rule where [a-z] means the same thing as [abcde...xyz].\n",
    "\n",
    "Here are some more:\n",
    "~~~ \n",
    "[0-9]        any numeric character\n",
    "[a-z]        any lowercase alphabetic character\n",
    "[A-Z]        any uppercase alphabetic character\n",
    "[aeiou]      any vowel (i.e. any character within the brackets)\n",
    "[0-9a-z]     to combine sets, list them one after another \n",
    "[^...]       exclude specific characters\n",
    "~~~\n",
    "\n",
    "\n",
    "You still may be wondering how the entirety of Sahit was able to be matched if only one character within [a-z] would match. The answer is something called a **quantifier**!\n",
    "\n",
    "Rules:\n",
    "~~~ \n",
    "*        0 or more of the preceding character/expression\n",
    "+        1 or more of the preceding character/expression\n",
    "?        0 or 1 of the preceding character/expression\n",
    "{n}      n copies of the preceding character/expression \n",
    "{n,m}    n to m copies of the preceding character/expression \n",
    "~~~\n",
    "\n",
    "Say that now, you only wanted to return Samuel when the name was mentioned at the beginning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BN1ZQwqCV7J",
    "outputId": "7f38c366-58e2-440b-85f3-9c53496fc486"
   },
   "outputs": [],
   "source": [
    "re.findall(r'^Samuel', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZMLtpFaCa-4"
   },
   "source": [
    "**Special characters**, such as the *^* which was just used in the pattern above, match strings that have a specific placement in a sentence. For example, *^* matches the subsequent pattern only if it is at the beginning of the string. This is why only a single 'Samuel' was returned.\n",
    "\n",
    "Rules:\n",
    "~~~ \n",
    ".         any single character except newline character\n",
    "^         start of string\n",
    "$         end of entire string\n",
    "\\n        new line\n",
    "\\r        carriage return\n",
    "\\t        tab\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojtbv71XCojp"
   },
   "source": [
    "**Python RegEx Methods**\n",
    "\n",
    "* `re.findall(pattern, string)`: Returns all phrases that match your pattern in the string.\n",
    "\n",
    "* `re.sub(pattern, replacment, string)`: Return the string after replacing the leftmost non-overlapping occurences of the pattern in string with replacement\n",
    "\n",
    "* `re.split(pattern, string)`: Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYqg1kc1Iv8j"
   },
   "source": [
    "# Part 4: Concordances and Collocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igkvUNygJVSq"
   },
   "source": [
    "## Concordances\n",
    "A concordance view shows us every occurrence of a given word, together with some context. Concordances are fundamnetally important if we want to understand the meaning of a word in a context.\n",
    "\n",
    "Here we look up the word \"petition\" in casebody of the California Dataset by entering text followed by a period, then the term concordance, and then placing “petition” in parentheses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:42:00.999872Z",
     "start_time": "2022-08-22T10:42:00.987882Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qq7Oag4tJGaU",
    "outputId": "e79058b0-2b2f-4ec2-c858-6b384e1cd6a8"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize # import tokenizer function from nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we created a dataframe called **df** which consists of downloaded cases from Hawaii. \n",
    "We will now try to access the text of those decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:41:11.112886Z",
     "start_time": "2022-08-22T10:41:11.092599Z"
    }
   },
   "outputs": [],
   "source": [
    "case_body = df['casebody'][0]['data']['opinions'][0]['text'] # this function looks into casebody column\n",
    "                                                             # first elememnt in it, aka [0], then 'data', then 'opinions'\n",
    "                                                             # then the first element again [0], then text\n",
    "                                                             # basically - it's complex data structure - \n",
    "                                                             # a dictionary with a list with a dicitonary with a list!\n",
    "case_body[:10000] ## print the first 10000 characters of this text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:42:08.549641Z",
     "start_time": "2022-08-22T10:42:08.485616Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JM0A4YP_JKj_",
    "outputId": "1c41ff03-265c-4b71-b2f9-c10fb483a23a"
   },
   "outputs": [],
   "source": [
    "case_body_tokenized = word_tokenize(case_body)\n",
    "text = Text(case_body_tokenized)\n",
    "text.concordance(\"petition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEAq9YRTjFHH"
   },
   "source": [
    "**Question 6: write your own code to explore the occurence of the word *court***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtPjYeCwjGWQ",
    "outputId": "10d17730-2e86-498d-fcbb-62268d4f4555"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTR1I6NpaxZt"
   },
   "source": [
    "## Collocation\n",
    "Collocations are expressions of multiple words which commonly co-occur. For example, the top ten bigram collocations in casebody of the downloaded case.law dataset are listed below, as measured using **Pointwise Mutual Information**. \n",
    "\n",
    "[A pretty good explanation of PMI](https://stats.stackexchange.com/a/522504) is given on **stackexchange.**\n",
    "\n",
    "Note: stackexchange (and google generally) is a wonderful resource for all things relating to NLP and statistics. Although for this course, I do not emphasize concrete statistical knoweldge or mathematical formulas, you should still get some **intuitive** understanding of what these measures like PMI do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:46:36.232201Z",
     "start_time": "2022-08-22T10:46:36.228226Z"
    },
    "id": "AWJNDIOIJNED"
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "fourgram_measures = nltk.collocations.QuadgramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-22T10:46:43.125438Z",
     "start_time": "2022-08-22T10:46:43.085474Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSsFAHq2JPtl",
    "outputId": "78ee1dac-e3bc-4675-df13-2179bce20cfb"
   },
   "outputs": [],
   "source": [
    "bigram_finder = BigramCollocationFinder.from_words(case_body_tokenized)\n",
    "bigram_finder.nbest(bigram_measures.pmi, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any interesting patterns that emerge from the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu7RXh6pjW_t"
   },
   "source": [
    "**Question 7: Using the methods defined above, find the top 10 trigram and fourgram collocations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lk2b-A0qJSRh"
   },
   "outputs": [],
   "source": [
    "# Trigram\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq0OZCEHDnCH"
   },
   "outputs": [],
   "source": [
    "# FourGram\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fND5UzC7C_SH"
   },
   "source": [
    "Congratulations! You have finished Lab 1!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab1 : Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
